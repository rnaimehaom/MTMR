{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "89839aa7",
   "metadata": {},
   "source": [
    "# Tutorial - Step2 : MTMR finetuning with Reinforcement learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f1191ab",
   "metadata": {},
   "source": [
    "## 1. Import requirements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b3084e37",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import torch\n",
    "import time\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "693d49a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from MTMR.dataset import TrainingSmilesDataset, ValidationSmilesDataset\n",
    "from MTMR.vae import SmilesAutoencoder, RewardFunctionLogP\n",
    "from MTMR.properties import penalized_logp, similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f087dc93",
   "metadata": {},
   "source": [
    "## 2. Configure GPU (if available)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e543aa03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "use_cuda = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda:0\" if use_cuda else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f5ef309",
   "metadata": {},
   "source": [
    "## 3. Specify a target property"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7998c0ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "PROPERTY_NAME = \"logp06\"\n",
    "\n",
    "SCORING_PROPERTY_FT = penalized_logp\n",
    "SCORING_TANIMOTO_FT = similarity\n",
    "\n",
    "## Configure the parameters of a reward function for the target property\n",
    "threshold_property = 0.\n",
    "threshold_similarity = 0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16f6beb9",
   "metadata": {},
   "source": [
    "## 4. Set directories (for inputs and outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "297ae962",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_data_dir = os.path.join(\"DATA\", PROPERTY_NAME)\n",
    "input_ckpt_dir = os.path.join(\"outputs_Tutorial_1_MTMR_pretraining_latent8\", PROPERTY_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4a049417",
   "metadata": {},
   "outputs": [],
   "source": [
    "_output_dir = \"outputs_Tutorial_2_MTMR_finetuning_latent8\"\n",
    "if not os.path.exists(_output_dir):\n",
    "    os.mkdir(_output_dir)\n",
    "\n",
    "output_dir = os.path.join(_output_dir, PROPERTY_NAME)\n",
    "if not os.path.exists(output_dir):\n",
    "    os.mkdir(output_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78d87375",
   "metadata": {},
   "source": [
    "## 5. Set file names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8d4fff29",
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath_train = os.path.join(input_data_dir, \"rdkit_train_triplet.txt\")\n",
    "filepath_valid = os.path.join(input_data_dir, \"rdkit_valid.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f257357c",
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath_pretrain_ckpt     = os.path.join(input_ckpt_dir, \"checkpoints.pt\")\n",
    "filepath_pretrain_configs  = os.path.join(input_ckpt_dir, \"configs.csv\")\n",
    "filepath_pretrain_char2idx = os.path.join(input_ckpt_dir, \"char2idx.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "769eebfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath_char2idx      = os.path.join(output_dir, \"char2idx.csv\")\n",
    "filepath_configs       = os.path.join(output_dir, \"configs.csv\")\n",
    "filepath_checkpoint    = os.path.join(output_dir, \"checkpoints.pt\")\n",
    "filepath_history       = os.path.join(output_dir, \"history.csv\")\n",
    "filepath_history_valid = os.path.join(output_dir, \"history_valid.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c4c7634",
   "metadata": {},
   "source": [
    "## 6. Load datasets (for training and validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cf1c3b0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = TrainingSmilesDataset(filepath_train, filepath_char2idx=filepath_pretrain_char2idx, device=device)\n",
    "dataset.save_char2idx(filepath_char2idx)\n",
    "dataset_valid = ValidationSmilesDataset(filepath_valid, filepath_char2idx, device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60775df5",
   "metadata": {},
   "source": [
    "## 7. Load a pretrained generator of MTMR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "375a1a7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Model configuration\n",
    "model_configs = {\"hidden_size\"    :None,\n",
    "                 \"latent_size\"    :None,\n",
    "                 \"num_layers\"     :None,\n",
    "                 \"vocab_size\"     :None,\n",
    "                 \"sos_idx\"        :None,\n",
    "                 \"eos_idx\"        :None,\n",
    "                 \"pad_idx\"        :None,\n",
    "                 \"device\"         :device,\n",
    "                 \"filepath_config\":filepath_pretrain_configs}\n",
    "\n",
    "## Model initialization\n",
    "generator = SmilesAutoencoder(**model_configs)\n",
    "\n",
    "## Load pretrained model\n",
    "generator.load_model(filepath_pretrain_ckpt)\n",
    "\n",
    "## Configuration save\n",
    "generator.save_config(filepath_configs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad5d0980",
   "metadata": {},
   "source": [
    "## 8. Define a reward function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7db45199",
   "metadata": {},
   "outputs": [],
   "source": [
    "reward_ft = RewardFunctionLogP(similarity_ft=SCORING_TANIMOTO_FT,\n",
    "                               scoring_ft=SCORING_PROPERTY_FT,\n",
    "                               threshold_property=threshold_property,\n",
    "                               threshold_similarity=threshold_similarity)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf150994",
   "metadata": {},
   "source": [
    "## 9. Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b6bf965a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[000000/002000]  loss: 0.646  reward: 1.832  similarity: 0.640  property[0]: 1.832  valid_ratio(va): 1.000  similarity(va): 0.195  property(va): 2.582\n",
      "[000010/002000]  loss: 0.592  reward: 1.815  similarity: 0.636  property[0]: 1.815  valid_ratio(va): 1.000  similarity(va): 0.193  property(va): 2.876\n",
      "[000020/002000]  loss: 0.607  reward: 1.970  similarity: 0.640  property[0]: 1.970  valid_ratio(va): 1.000  similarity(va): 0.190  property(va): 3.075\n",
      "[000030/002000]  loss: 0.600  reward: 1.946  similarity: 0.636  property[0]: 1.946  valid_ratio(va): 1.000  similarity(va): 0.187  property(va): 3.096\n",
      "[000040/002000]  loss: 0.591  reward: 1.870  similarity: 0.638  property[0]: 1.870  valid_ratio(va): 1.000  similarity(va): 0.188  property(va): 3.169\n",
      "[000050/002000]  loss: 0.576  reward: 1.930  similarity: 0.639  property[0]: 1.930  valid_ratio(va): 1.000  similarity(va): 0.188  property(va): 3.119\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-aab22924c17f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m df_history, df_history_valid = generator.policy_gradient(dataset, reward_ft,\n\u001b[1;32m      2\u001b[0m                                                          \u001b[0mvalidation_dataset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdataset_valid\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m                                                          checkpoint_filepath=filepath_checkpoint)\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mdf_history\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_history\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Data1/descartes/MTMR/MTMR/vae.py\u001b[0m in \u001b[0;36mpolicy_gradient\u001b[0;34m(self, dataset, reward_ft, batch_size, total_steps, learning_rate, discount_factor, buffer_size, buffer_batch_size, validation_dataset, validation_repetition_size, use_adaptive_threshold, checkpoint_step, checkpoint_filepath, display_step, verbose)\u001b[0m\n\u001b[1;32m    447\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    448\u001b[0m                 \u001b[0;31m## generate target data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 449\u001b[0;31m                 \u001b[0mbatch_out_encode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_inp_encode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_inp_length\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# batch_out_encode.shape = (sample, max_seqlen)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    450\u001b[0m                 \u001b[0mbatch_tar_smiles\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msos_char\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msmi\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meos_char\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msmi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_out_encode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;31m# len(batch_tar_smiles) = batch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    451\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Data1/descartes/MTMR/MTMR/vae.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, smiles, length, max_seqlen)\u001b[0m\n\u001b[1;32m    843\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    844\u001b[0m                 \u001b[0mz_i\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mz\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# z_i.shape = (1, latent)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 845\u001b[0;31m                 \u001b[0mseq\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_generate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz_i\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_seqlen\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# seq.shape = (1, max_seqlen)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    846\u001b[0m                 \u001b[0mseq\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mseq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    847\u001b[0m                 \u001b[0mgenerated\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Data1/descartes/MTMR/MTMR/vae.py\u001b[0m in \u001b[0;36m_generate\u001b[0;34m(self, z, max_seqlen, greedy)\u001b[0m\n\u001b[1;32m    878\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    879\u001b[0m             \u001b[0;31m## Decode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 880\u001b[0;31m             \u001b[0mlogits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhiddens\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mz\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhiddens\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# logits.shape = (batch, 1, vocab), hiddens.shape = (numlayer, batch, hidden)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    881\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    882\u001b[0m             \u001b[0;31m## Next word\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/MTMR/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Data1/descartes/MTMR/MTMR/vae.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, inp, z, hidden)\u001b[0m\n\u001b[1;32m    308\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mz\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    309\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 310\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_single\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mz\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    311\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    312\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Data1/descartes/MTMR/MTMR/vae.py\u001b[0m in \u001b[0;36m_forward_single\u001b[0;34m(self, inp, hidden, z)\u001b[0m\n\u001b[1;32m    361\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    362\u001b[0m         \u001b[0;31m## Decoder - Teacher forcing\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 363\u001b[0;31m         \u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrnn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# out.shape = (batch, 1, hidden), hidden.shape = (numlayer, batch, hidden)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    364\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    365\u001b[0m         \u001b[0;31m## Prediction\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/MTMR/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/MTMR/lib/python3.6/site-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m    848\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbatch_sizes\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    849\u001b[0m             result = _VF.gru(input, hx, self._flat_weights, self.bias, self.num_layers,\n\u001b[0;32m--> 850\u001b[0;31m                              self.dropout, self.training, self.bidirectional, self.batch_first)\n\u001b[0m\u001b[1;32m    851\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    852\u001b[0m             result = _VF.gru(input, batch_sizes, hx, self._flat_weights, self.bias,\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "df_history, df_history_valid = generator.policy_gradient(dataset, reward_ft,\n",
    "                                                         validation_dataset=dataset_valid,\n",
    "                                                         checkpoint_filepath=filepath_checkpoint)\n",
    "\n",
    "df_history.to_csv(filepath_history, index=False)\n",
    "df_history_valid.to_csv(filepath_history_valid, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcd2a6ca",
   "metadata": {},
   "source": [
    "## 10. Visualize for reward & loss analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b09331b",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(4,1,figsize=(8,8))\n",
    "\n",
    "axes[0].plot(df_history.loc[:,\"LOSS\"], label=\"Loss\")\n",
    "axes[1].plot(df_history.loc[:,\"REWARD\"], label=\"Reward\")\n",
    "axes[2].plot(df_history.loc[:,\"SIMILARITY\"], label=\"Tanimoto Coeff.\")\n",
    "axes[3].plot(df_history.loc[:,\"PROPERTY\"], label=f\"Property ({PROPERTY_NAME})\")\n",
    "\n",
    "axes[3].set_xlabel(\"Iteration\")\n",
    "for ax in axes:\n",
    "    ax.legend(loc='best')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e146da6",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(3,1,figsize=(8,4))\n",
    "\n",
    "axes[0].plot(df_history_valid.loc[:,\"VALID_RATIO\"], label=\"Validity\")\n",
    "axes[1].plot(df_history_valid.loc[:,\"AVERAGE_SIMILARITY\"], label=\"Tanimoto coeff.\")\n",
    "axes[2].plot(df_history_valid.loc[:,\"AVERAGE_PROPERTY\"], label=f\"Property ({PROPERTY_NAME})\")\n",
    "\n",
    "axes[0].set_ylim(0.95, 1.005)\n",
    "\n",
    "axes[2].set_xlabel(\"Iteration\")\n",
    "for ax in axes:\n",
    "    ax.legend(loc='best')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd0ca318",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
