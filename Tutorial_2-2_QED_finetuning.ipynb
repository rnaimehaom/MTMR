{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c392c41a",
   "metadata": {},
   "source": [
    "# Tutorial - Step2 : MTMR finetuning with Reinforcement learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "454c7c96",
   "metadata": {},
   "source": [
    "## 1. Import requirements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ce232a72",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import torch\n",
    "import time\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cafefbdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from MTMR.dataset import TrainingSmilesDataset, ValidationSmilesDataset\n",
    "from MTMR.vae import SmilesAutoencoder, RewardFunction\n",
    "from MTMR.properties import drd2, qed, similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cd39a1b",
   "metadata": {},
   "source": [
    "## 2. Configure GPU (if available)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b035e655",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "use_cuda = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda:0\" if use_cuda else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c43c98f6",
   "metadata": {},
   "source": [
    "## 3. Specify a target property"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a2b2f0ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "PROPERTY_NAME = \"qed\"\n",
    "\n",
    "SCORING_PROPERTY_FT = qed\n",
    "SCORING_TANIMOTO_FT = similarity\n",
    "\n",
    "## Configure the parameters of a reward function for the target property\n",
    "threshold_property = 0.75\n",
    "threshold_similarity = 0.3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea6e78b4",
   "metadata": {},
   "source": [
    "## 4. Set directories (for inputs and outputs)Â¶"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fe158b0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_data_dir = os.path.join(\"DATA\", PROPERTY_NAME)\n",
    "input_ckpt_dir = os.path.join(\"outputs_Tutorial_1_MTMR_pretraining\", PROPERTY_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "daa97fec",
   "metadata": {},
   "outputs": [],
   "source": [
    "_output_dir = \"outputs_Tutorial_2_MTMR_finetuning\"\n",
    "if not os.path.exists(_output_dir):\n",
    "    os.mkdir(_output_dir)\n",
    "\n",
    "output_dir = os.path.join(_output_dir, PROPERTY_NAME)\n",
    "if not os.path.exists(output_dir):\n",
    "    os.mkdir(output_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ee1f431",
   "metadata": {},
   "source": [
    "## 5. Set file names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f33c8f39",
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath_train = os.path.join(input_data_dir, \"rdkit_train_triplet.txt\")\n",
    "filepath_valid = os.path.join(input_data_dir, \"rdkit_valid.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3d9c9c6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath_pretrain_ckpt     = os.path.join(input_ckpt_dir, \"checkpoints.pt\")\n",
    "filepath_pretrain_configs  = os.path.join(input_ckpt_dir, \"configs.csv\")\n",
    "filepath_pretrain_char2idx = os.path.join(input_ckpt_dir, \"char2idx.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7a7beb72",
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath_char2idx      = os.path.join(output_dir, \"char2idx.csv\")\n",
    "filepath_configs       = os.path.join(output_dir, \"configs.csv\")\n",
    "filepath_checkpoint    = os.path.join(output_dir, \"checkpoints.pt\")\n",
    "filepath_history       = os.path.join(output_dir, \"history.csv\")\n",
    "filepath_history_valid = os.path.join(output_dir, \"history_valid.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45f3256a",
   "metadata": {},
   "source": [
    "## 6. Load datasets (for training and validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d7235bc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = TrainingSmilesDataset(filepath_train, filepath_char2idx=filepath_pretrain_char2idx, device=device)\n",
    "dataset.save_char2idx(filepath_char2idx)\n",
    "dataset_valid = ValidationSmilesDataset(filepath_valid, filepath_char2idx, device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93b2a7a5",
   "metadata": {},
   "source": [
    "## 7. Load a pretrained generator of MTMR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3678c3b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Model configuration\n",
    "model_configs = {\"hidden_size\"    :None,\n",
    "                 \"latent_size\"    :None,\n",
    "                 \"num_layers\"     :None,\n",
    "                 \"vocab_size\"     :None,\n",
    "                 \"sos_idx\"        :None,\n",
    "                 \"eos_idx\"        :None,\n",
    "                 \"pad_idx\"        :None,\n",
    "                 \"device\"         :device,\n",
    "                 \"filepath_config\":filepath_pretrain_configs}\n",
    "\n",
    "## Model initialization\n",
    "generator = SmilesAutoencoder(**model_configs)\n",
    "\n",
    "## Load pretrained model\n",
    "generator.load_model(filepath_pretrain_ckpt)\n",
    "\n",
    "## Configuration save\n",
    "generator.save_config(filepath_configs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00311408",
   "metadata": {},
   "source": [
    "## 8. Define a reward function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "989178db",
   "metadata": {},
   "outputs": [],
   "source": [
    "reward_ft = RewardFunction(similarity_ft=SCORING_TANIMOTO_FT,\n",
    "                           scoring_ft=SCORING_PROPERTY_FT,\n",
    "                           threshold_property=threshold_property,\n",
    "                           threshold_similarity=threshold_similarity)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ba2d913",
   "metadata": {},
   "source": [
    "## 9. Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7ee070f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[000000/002000]  loss: 0.040  reward: 0.499  similarity: 0.612  property: 0.818  valid_ratio(va): 0.997  similarity(va): 0.403  property(va): 0.754\n",
      "[000010/002000]  loss: 0.036  reward: 0.514  similarity: 0.635  property: 0.819  valid_ratio(va): 1.000  similarity(va): 0.414  property(va): 0.772\n",
      "[000020/002000]  loss: 0.037  reward: 0.561  similarity: 0.633  property: 0.827  valid_ratio(va): 1.000  similarity(va): 0.404  property(va): 0.774\n",
      "[000030/002000]  loss: 0.040  reward: 0.573  similarity: 0.595  property: 0.837  valid_ratio(va): 0.997  similarity(va): 0.407  property(va): 0.793\n",
      "[000040/002000]  loss: 0.041  reward: 0.616  similarity: 0.569  property: 0.842  valid_ratio(va): 1.000  similarity(va): 0.399  property(va): 0.795\n",
      "[000050/002000]  loss: 0.043  reward: 0.592  similarity: 0.559  property: 0.843  valid_ratio(va): 1.000  similarity(va): 0.398  property(va): 0.799\n",
      "[000060/002000]  loss: 0.042  reward: 0.648  similarity: 0.536  property: 0.853  valid_ratio(va): 1.000  similarity(va): 0.383  property(va): 0.806\n",
      "[000070/002000]  loss: 0.041  reward: 0.637  similarity: 0.568  property: 0.844  valid_ratio(va): 1.000  similarity(va): 0.382  property(va): 0.813\n",
      "[000080/002000]  loss: 0.042  reward: 0.676  similarity: 0.544  property: 0.856  valid_ratio(va): 1.000  similarity(va): 0.381  property(va): 0.807\n",
      "[000090/002000]  loss: 0.041  reward: 0.679  similarity: 0.519  property: 0.858  valid_ratio(va): 0.997  similarity(va): 0.387  property(va): 0.808\n",
      "[000100/002000]  loss: 0.046  reward: 0.674  similarity: 0.497  property: 0.858  valid_ratio(va): 1.000  similarity(va): 0.391  property(va): 0.809\n",
      "[000110/002000]  loss: 0.041  reward: 0.672  similarity: 0.552  property: 0.852  valid_ratio(va): 1.000  similarity(va): 0.386  property(va): 0.818\n",
      "[000120/002000]  loss: 0.043  reward: 0.699  similarity: 0.546  property: 0.856  valid_ratio(va): 1.000  similarity(va): 0.372  property(va): 0.816\n",
      "[000130/002000]  loss: 0.041  reward: 0.674  similarity: 0.530  property: 0.857  valid_ratio(va): 0.997  similarity(va): 0.389  property(va): 0.813\n",
      "[000140/002000]  loss: 0.042  reward: 0.672  similarity: 0.527  property: 0.854  valid_ratio(va): 1.000  similarity(va): 0.388  property(va): 0.818\n",
      "[000150/002000]  loss: 0.044  reward: 0.675  similarity: 0.519  property: 0.856  valid_ratio(va): 1.000  similarity(va): 0.387  property(va): 0.816\n",
      "[000160/002000]  loss: 0.042  reward: 0.721  similarity: 0.512  property: 0.863  valid_ratio(va): 0.997  similarity(va): 0.383  property(va): 0.820\n",
      "[000170/002000]  loss: 0.041  reward: 0.704  similarity: 0.522  property: 0.865  valid_ratio(va): 0.997  similarity(va): 0.386  property(va): 0.825\n",
      "[000180/002000]  loss: 0.038  reward: 0.677  similarity: 0.548  property: 0.855  valid_ratio(va): 1.000  similarity(va): 0.371  property(va): 0.815\n",
      "[000190/002000]  loss: 0.044  reward: 0.703  similarity: 0.514  property: 0.862  valid_ratio(va): 1.000  similarity(va): 0.377  property(va): 0.821\n",
      "[000200/002000]  loss: 0.044  reward: 0.710  similarity: 0.494  property: 0.859  valid_ratio(va): 1.000  similarity(va): 0.377  property(va): 0.830\n",
      "[000210/002000]  loss: 0.039  reward: 0.714  similarity: 0.530  property: 0.862  valid_ratio(va): 1.000  similarity(va): 0.376  property(va): 0.821\n",
      "[000220/002000]  loss: 0.042  reward: 0.703  similarity: 0.517  property: 0.858  valid_ratio(va): 1.000  similarity(va): 0.377  property(va): 0.826\n",
      "[000230/002000]  loss: 0.041  reward: 0.702  similarity: 0.508  property: 0.861  valid_ratio(va): 1.000  similarity(va): 0.372  property(va): 0.826\n",
      "[000240/002000]  loss: 0.044  reward: 0.708  similarity: 0.516  property: 0.861  valid_ratio(va): 1.000  similarity(va): 0.376  property(va): 0.826\n",
      "[000250/002000]  loss: 0.041  reward: 0.665  similarity: 0.506  property: 0.857  valid_ratio(va): 1.000  similarity(va): 0.368  property(va): 0.831\n",
      "[000260/002000]  loss: 0.044  reward: 0.718  similarity: 0.518  property: 0.864  valid_ratio(va): 1.000  similarity(va): 0.374  property(va): 0.830\n",
      "[000270/002000]  loss: 0.039  reward: 0.694  similarity: 0.538  property: 0.860  valid_ratio(va): 1.000  similarity(va): 0.373  property(va): 0.826\n",
      "[000280/002000]  loss: 0.042  reward: 0.702  similarity: 0.501  property: 0.861  valid_ratio(va): 1.000  similarity(va): 0.374  property(va): 0.837\n",
      "[000290/002000]  loss: 0.043  reward: 0.688  similarity: 0.523  property: 0.857  valid_ratio(va): 1.000  similarity(va): 0.374  property(va): 0.832\n",
      "[000300/002000]  loss: 0.045  reward: 0.738  similarity: 0.492  property: 0.869  valid_ratio(va): 1.000  similarity(va): 0.367  property(va): 0.836\n",
      "[000310/002000]  loss: 0.045  reward: 0.707  similarity: 0.502  property: 0.865  valid_ratio(va): 1.000  similarity(va): 0.375  property(va): 0.835\n",
      "[000320/002000]  loss: 0.045  reward: 0.717  similarity: 0.509  property: 0.867  valid_ratio(va): 1.000  similarity(va): 0.372  property(va): 0.834\n",
      "[000330/002000]  loss: 0.042  reward: 0.731  similarity: 0.500  property: 0.866  valid_ratio(va): 1.000  similarity(va): 0.377  property(va): 0.833\n",
      "[000340/002000]  loss: 0.044  reward: 0.677  similarity: 0.505  property: 0.863  valid_ratio(va): 1.000  similarity(va): 0.364  property(va): 0.832\n",
      "[000350/002000]  loss: 0.044  reward: 0.740  similarity: 0.526  property: 0.873  valid_ratio(va): 1.000  similarity(va): 0.373  property(va): 0.831\n",
      "[000360/002000]  loss: 0.040  reward: 0.728  similarity: 0.533  property: 0.864  valid_ratio(va): 1.000  similarity(va): 0.370  property(va): 0.837\n",
      "[000370/002000]  loss: 0.039  reward: 0.737  similarity: 0.527  property: 0.868  valid_ratio(va): 1.000  similarity(va): 0.372  property(va): 0.829\n",
      "[000380/002000]  loss: 0.045  reward: 0.761  similarity: 0.505  property: 0.875  valid_ratio(va): 1.000  similarity(va): 0.369  property(va): 0.834\n",
      "[000390/002000]  loss: 0.044  reward: 0.717  similarity: 0.519  property: 0.864  valid_ratio(va): 1.000  similarity(va): 0.369  property(va): 0.837\n",
      "[000400/002000]  loss: 0.042  reward: 0.719  similarity: 0.478  property: 0.862  valid_ratio(va): 1.000  similarity(va): 0.383  property(va): 0.839\n",
      "[000410/002000]  loss: 0.040  reward: 0.754  similarity: 0.511  property: 0.873  valid_ratio(va): 1.000  similarity(va): 0.370  property(va): 0.841\n",
      "[000420/002000]  loss: 0.044  reward: 0.727  similarity: 0.494  property: 0.862  valid_ratio(va): 1.000  similarity(va): 0.380  property(va): 0.832\n",
      "[000430/002000]  loss: 0.041  reward: 0.686  similarity: 0.512  property: 0.863  valid_ratio(va): 1.000  similarity(va): 0.359  property(va): 0.837\n"
     ]
    }
   ],
   "source": [
    "df_history, df_history_valid = generator.policy_gradient(dataset, reward_ft,\n",
    "                                                         validation_dataset=dataset_valid,\n",
    "                                                         scoring_ft=SCORING_PROPERTY_FT,\n",
    "                                                         checkpoint_filepath=filepath_checkpoint)\n",
    "\n",
    "df_history.to_csv(filepath_history, index=False)\n",
    "df_history_valid.to_csv(filepath_history_valid, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "982770a7",
   "metadata": {},
   "source": [
    "## 10. Visualize for reward & loss analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e48c355",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(4,1,figsize=(8,8))\n",
    "\n",
    "axes[0].plot(df_history.loc[:,\"LOSS\"], label=\"Loss\")\n",
    "axes[1].plot(df_history.loc[:,\"REWARD\"], label=\"Reward\")\n",
    "axes[2].plot(df_history.loc[:,\"SIMILARITY\"], label=\"Tanimoto Coeff.\")\n",
    "axes[3].plot(df_history.loc[:,\"PROPERTY\"], label=f\"Property ({PROPERTY_NAME})\")\n",
    "\n",
    "axes[3].set_xlabel(\"Iteration\")\n",
    "for ax in axes:\n",
    "    ax.legend(loc='best')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aea3557",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(3,1,figsize=(8,4))\n",
    "\n",
    "axes[0].plot(df_history_valid.loc[:,\"VALID_RATIO\"], label=\"Validity\")\n",
    "axes[1].plot(df_history_valid.loc[:,\"AVERAGE_SIMILARITY\"], label=\"Tanimoto coeff.\")\n",
    "axes[2].plot(df_history_valid.loc[:,\"AVERAGE_PROPERTY\"], label=f\"Property ({PROPERTY_NAME})\")\n",
    "\n",
    "axes[2].set_xlabel(\"Iteration\")\n",
    "for ax in axes:\n",
    "    ax.legend(loc='best')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
