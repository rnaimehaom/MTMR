{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "89839aa7",
   "metadata": {},
   "source": [
    "# Tutorial - Step2 : MTMR finetuning with Reinforcement learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f1191ab",
   "metadata": {},
   "source": [
    "## 1. Import requirements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b3084e37",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import torch\n",
    "import time\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "693d49a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from MTMR.dataset import TrainingSmilesDataset, ValidationSmilesDataset\n",
    "from MTMR.vae import SmilesAutoencoder, RewardFunctionLogP\n",
    "from MTMR.properties import penalized_logp, similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f087dc93",
   "metadata": {},
   "source": [
    "## 2. Configure GPU (if available)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e543aa03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "use_cuda = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda:0\" if use_cuda else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f5ef309",
   "metadata": {},
   "source": [
    "## 3. Specify a target property"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7998c0ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "PROPERTY_NAME = \"logp04\"\n",
    "\n",
    "SCORING_PROPERTY_FT = penalized_logp\n",
    "SCORING_TANIMOTO_FT = similarity\n",
    "\n",
    "## Configure the parameters of a reward function for the target property\n",
    "threshold_property = 0.\n",
    "threshold_similarity = 0.3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16f6beb9",
   "metadata": {},
   "source": [
    "## 4. Set directories (for inputs and outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "297ae962",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_data_dir = os.path.join(\"DATA\", PROPERTY_NAME)\n",
    "input_ckpt_dir = os.path.join(\"outputs_Tutorial_1_MTMR_pretraining_latent8\", PROPERTY_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4a049417",
   "metadata": {},
   "outputs": [],
   "source": [
    "_output_dir = \"outputs_Tutorial_2_MTMR_finetuning_latent8\"\n",
    "if not os.path.exists(_output_dir):\n",
    "    os.mkdir(_output_dir)\n",
    "\n",
    "output_dir = os.path.join(_output_dir, PROPERTY_NAME)\n",
    "if not os.path.exists(output_dir):\n",
    "    os.mkdir(output_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78d87375",
   "metadata": {},
   "source": [
    "## 5. Set file names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8d4fff29",
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath_train = os.path.join(input_data_dir, \"rdkit_train_triplet.txt\")\n",
    "filepath_valid = os.path.join(input_data_dir, \"rdkit_valid.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f257357c",
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath_pretrain_ckpt     = os.path.join(input_ckpt_dir, \"checkpoints.pt\")\n",
    "filepath_pretrain_configs  = os.path.join(input_ckpt_dir, \"configs.csv\")\n",
    "filepath_pretrain_char2idx = os.path.join(input_ckpt_dir, \"char2idx.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "769eebfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath_char2idx      = os.path.join(output_dir, \"char2idx.csv\")\n",
    "filepath_configs       = os.path.join(output_dir, \"configs.csv\")\n",
    "filepath_checkpoint    = os.path.join(output_dir, \"checkpoints.pt\")\n",
    "filepath_history       = os.path.join(output_dir, \"history.csv\")\n",
    "filepath_history_valid = os.path.join(output_dir, \"history_valid.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c4c7634",
   "metadata": {},
   "source": [
    "## 6. Load datasets (for training and validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cf1c3b0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = TrainingSmilesDataset(filepath_train, filepath_char2idx=filepath_pretrain_char2idx, device=device)\n",
    "dataset.save_char2idx(filepath_char2idx)\n",
    "dataset_valid = ValidationSmilesDataset(filepath_valid, filepath_char2idx, device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60775df5",
   "metadata": {},
   "source": [
    "## 7. Load a pretrained generator of MTMR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "375a1a7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Model configuration\n",
    "model_configs = {\"hidden_size\"    :None,\n",
    "                 \"latent_size\"    :None,\n",
    "                 \"num_layers\"     :None,\n",
    "                 \"vocab_size\"     :None,\n",
    "                 \"sos_idx\"        :None,\n",
    "                 \"eos_idx\"        :None,\n",
    "                 \"pad_idx\"        :None,\n",
    "                 \"device\"         :device,\n",
    "                 \"filepath_config\":filepath_pretrain_configs}\n",
    "\n",
    "## Model initialization\n",
    "generator = SmilesAutoencoder(**model_configs)\n",
    "\n",
    "## Load pretrained model\n",
    "generator.load_model(filepath_pretrain_ckpt)\n",
    "\n",
    "## Configuration save\n",
    "generator.save_config(filepath_configs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad5d0980",
   "metadata": {},
   "source": [
    "## 8. Define a reward function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7db45199",
   "metadata": {},
   "outputs": [],
   "source": [
    "reward_ft = RewardFunctionLogP(similarity_ft=SCORING_TANIMOTO_FT,\n",
    "                               scoring_ft=SCORING_PROPERTY_FT,\n",
    "                               threshold_property=threshold_property,\n",
    "                               threshold_similarity=threshold_similarity)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf150994",
   "metadata": {},
   "source": [
    "## 9. Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b6bf965a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[000000/002000]  loss: 0.870  reward: 2.768  similarity: 0.388  property[0]: 2.768  valid_ratio(va): 1.000  similarity(va): 0.187  property(va): 2.518\n",
      "[000010/002000]  loss: 0.771  reward: 3.057  similarity: 0.392  property[0]: 3.057  valid_ratio(va): 1.000  similarity(va): 0.192  property(va): 3.058\n",
      "[000020/002000]  loss: 0.764  reward: 3.101  similarity: 0.389  property[0]: 3.101  valid_ratio(va): 1.000  similarity(va): 0.193  property(va): 3.312\n",
      "[000030/002000]  loss: 0.709  reward: 3.146  similarity: 0.388  property[0]: 3.146  valid_ratio(va): 1.000  similarity(va): 0.192  property(va): 3.484\n",
      "[000040/002000]  loss: 0.766  reward: 3.365  similarity: 0.386  property[0]: 3.365  valid_ratio(va): 1.000  similarity(va): 0.192  property(va): 3.578\n",
      "[000050/002000]  loss: 0.716  reward: 3.150  similarity: 0.390  property[0]: 3.150  valid_ratio(va): 1.000  similarity(va): 0.192  property(va): 3.630\n",
      "[000060/002000]  loss: 0.719  reward: 3.116  similarity: 0.389  property[0]: 3.116  valid_ratio(va): 1.000  similarity(va): 0.192  property(va): 3.749\n",
      "[000070/002000]  loss: 0.752  reward: 3.440  similarity: 0.390  property[0]: 3.440  valid_ratio(va): 1.000  similarity(va): 0.196  property(va): 3.783\n",
      "[000080/002000]  loss: 0.702  reward: 3.141  similarity: 0.388  property[0]: 3.141  valid_ratio(va): 1.000  similarity(va): 0.196  property(va): 3.784\n",
      "[000090/002000]  loss: 0.844  reward: 4.086  similarity: 0.385  property[0]: 4.086  valid_ratio(va): 1.000  similarity(va): 0.196  property(va): 3.919\n",
      "[000100/002000]  loss: 0.724  reward: 3.295  similarity: 0.389  property[0]: 3.295  valid_ratio(va): 1.000  similarity(va): 0.194  property(va): 3.931\n",
      "[000110/002000]  loss: 0.737  reward: 3.381  similarity: 0.394  property[0]: 3.381  valid_ratio(va): 1.000  similarity(va): 0.195  property(va): 3.946\n",
      "[000120/002000]  loss: 0.736  reward: 3.667  similarity: 0.390  property[0]: 3.667  valid_ratio(va): 1.000  similarity(va): 0.193  property(va): 3.963\n",
      "[000130/002000]  loss: 0.747  reward: 3.591  similarity: 0.394  property[0]: 3.591  valid_ratio(va): 1.000  similarity(va): 0.195  property(va): 3.988\n",
      "[000140/002000]  loss: 0.709  reward: 3.476  similarity: 0.388  property[0]: 3.476  valid_ratio(va): 1.000  similarity(va): 0.196  property(va): 3.965\n",
      "[000150/002000]  loss: 0.742  reward: 3.620  similarity: 0.393  property[0]: 3.620  valid_ratio(va): 1.000  similarity(va): 0.195  property(va): 3.992\n",
      "[000160/002000]  loss: 0.796  reward: 3.555  similarity: 0.388  property[0]: 3.555  valid_ratio(va): 1.000  similarity(va): 0.195  property(va): 4.032\n",
      "[000170/002000]  loss: 0.706  reward: 3.454  similarity: 0.394  property[0]: 3.454  valid_ratio(va): 1.000  similarity(va): 0.195  property(va): 4.042\n",
      "[000180/002000]  loss: 0.658  reward: 3.235  similarity: 0.389  property[0]: 3.235  valid_ratio(va): 1.000  similarity(va): 0.196  property(va): 4.079\n",
      "[000190/002000]  loss: 0.723  reward: 3.517  similarity: 0.388  property[0]: 3.517  valid_ratio(va): 1.000  similarity(va): 0.197  property(va): 4.051\n",
      "[000200/002000]  loss: 0.743  reward: 3.564  similarity: 0.385  property[0]: 3.564  valid_ratio(va): 1.000  similarity(va): 0.199  property(va): 4.056\n",
      "[000210/002000]  loss: 0.745  reward: 3.541  similarity: 0.387  property[0]: 3.541  valid_ratio(va): 1.000  similarity(va): 0.197  property(va): 4.046\n",
      "[000220/002000]  loss: 0.732  reward: 3.521  similarity: 0.387  property[0]: 3.521  valid_ratio(va): 1.000  similarity(va): 0.197  property(va): 4.071\n",
      "[000230/002000]  loss: 0.739  reward: 3.520  similarity: 0.386  property[0]: 3.520  valid_ratio(va): 1.000  similarity(va): 0.195  property(va): 4.051\n",
      "[000240/002000]  loss: 0.732  reward: 3.604  similarity: 0.391  property[0]: 3.604  valid_ratio(va): 1.000  similarity(va): 0.198  property(va): 4.124\n",
      "[000250/002000]  loss: 0.763  reward: 3.681  similarity: 0.396  property[0]: 3.681  valid_ratio(va): 1.000  similarity(va): 0.197  property(va): 4.085\n",
      "[000260/002000]  loss: 0.739  reward: 3.571  similarity: 0.385  property[0]: 3.571  valid_ratio(va): 1.000  similarity(va): 0.197  property(va): 4.120\n",
      "[000270/002000]  loss: 0.680  reward: 3.483  similarity: 0.385  property[0]: 3.483  valid_ratio(va): 1.000  similarity(va): 0.198  property(va): 4.100\n",
      "[000280/002000]  loss: 0.688  reward: 3.365  similarity: 0.389  property[0]: 3.365  valid_ratio(va): 1.000  similarity(va): 0.198  property(va): 4.135\n",
      "[000290/002000]  loss: 0.685  reward: 3.493  similarity: 0.399  property[0]: 3.493  valid_ratio(va): 1.000  similarity(va): 0.199  property(va): 4.062\n",
      "[000300/002000]  loss: 0.736  reward: 3.525  similarity: 0.385  property[0]: 3.525  valid_ratio(va): 1.000  similarity(va): 0.197  property(va): 4.107\n",
      "[000310/002000]  loss: 0.727  reward: 3.818  similarity: 0.393  property[0]: 3.818  valid_ratio(va): 1.000  similarity(va): 0.198  property(va): 4.122\n",
      "[000320/002000]  loss: 0.687  reward: 3.335  similarity: 0.389  property[0]: 3.335  valid_ratio(va): 1.000  similarity(va): 0.197  property(va): 4.140\n",
      "[000330/002000]  loss: 0.693  reward: 3.382  similarity: 0.392  property[0]: 3.382  valid_ratio(va): 1.000  similarity(va): 0.196  property(va): 4.138\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-aab22924c17f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m df_history, df_history_valid = generator.policy_gradient(dataset, reward_ft,\n\u001b[1;32m      2\u001b[0m                                                          \u001b[0mvalidation_dataset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdataset_valid\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m                                                          checkpoint_filepath=filepath_checkpoint)\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mdf_history\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_history\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Data1/descartes/MTMR/MTMR/vae.py\u001b[0m in \u001b[0;36mpolicy_gradient\u001b[0;34m(self, dataset, reward_ft, batch_size, total_steps, learning_rate, discount_factor, buffer_size, buffer_batch_size, validation_dataset, validation_repetition_size, use_adaptive_threshold, checkpoint_step, checkpoint_filepath, display_step, verbose)\u001b[0m\n\u001b[1;32m    447\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    448\u001b[0m                 \u001b[0;31m## generate target data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 449\u001b[0;31m                 \u001b[0mbatch_out_encode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_inp_encode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_inp_length\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# batch_out_encode.shape = (sample, max_seqlen)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    450\u001b[0m                 \u001b[0mbatch_tar_smiles\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msos_char\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msmi\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meos_char\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msmi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_out_encode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;31m# len(batch_tar_smiles) = batch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    451\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Data1/descartes/MTMR/MTMR/vae.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, smiles, length, max_seqlen)\u001b[0m\n\u001b[1;32m    843\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    844\u001b[0m                 \u001b[0mz_i\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mz\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# z_i.shape = (1, latent)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 845\u001b[0;31m                 \u001b[0mseq\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_generate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz_i\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_seqlen\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# seq.shape = (1, max_seqlen)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    846\u001b[0m                 \u001b[0mseq\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mseq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    847\u001b[0m                 \u001b[0mgenerated\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Data1/descartes/MTMR/MTMR/vae.py\u001b[0m in \u001b[0;36m_generate\u001b[0;34m(self, z, max_seqlen, greedy)\u001b[0m\n\u001b[1;32m    871\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_seqlen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    872\u001b[0m             \u001b[0;31m## Terminal condition\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 873\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0minps\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meos_idx\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0minps\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpad_idx\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    874\u001b[0m                 \u001b[0mouts\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meos_idx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    875\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "df_history, df_history_valid = generator.policy_gradient(dataset, reward_ft,\n",
    "                                                         validation_dataset=dataset_valid,\n",
    "                                                         checkpoint_filepath=filepath_checkpoint)\n",
    "\n",
    "df_history.to_csv(filepath_history, index=False)\n",
    "df_history_valid.to_csv(filepath_history_valid, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcd2a6ca",
   "metadata": {},
   "source": [
    "## 10. Visualize for reward & loss analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b09331b",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(4,1,figsize=(8,8))\n",
    "\n",
    "axes[0].plot(df_history.loc[:,\"LOSS\"], label=\"Loss\")\n",
    "axes[1].plot(df_history.loc[:,\"REWARD\"], label=\"Reward\")\n",
    "axes[2].plot(df_history.loc[:,\"SIMILARITY\"], label=\"Tanimoto Coeff.\")\n",
    "axes[3].plot(df_history.loc[:,\"PROPERTY\"], label=f\"Property ({PROPERTY_NAME})\")\n",
    "\n",
    "axes[3].set_xlabel(\"Iteration\")\n",
    "for ax in axes:\n",
    "    ax.legend(loc='best')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e146da6",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(3,1,figsize=(8,6))\n",
    "\n",
    "axes[0].plot(df_history_valid.loc[:,\"VALID_RATIO\"], label=\"Validity\")\n",
    "axes[1].plot(df_history_valid.loc[:,\"AVERAGE_SIMILARITY\"], label=\"Tanimoto coeff.\")\n",
    "axes[2].plot(df_history_valid.loc[:,\"AVERAGE_PROPERTY\"], label=f\"Property ({PROPERTY_NAME})\")\n",
    "\n",
    "axes[0].set_ylim(0.95, 1.005)\n",
    "\n",
    "axes[2].set_xlabel(\"Iteration\")\n",
    "for ax in axes:\n",
    "    ax.legend(loc='best')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd0ca318",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
